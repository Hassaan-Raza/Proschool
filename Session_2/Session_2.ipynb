{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Session 2 — Memory & Retrieval Basics in LangChain\n",
    "\n",
    "## Focus: Add long-term context and ground answers with documents\n",
    "\n",
    "In this session, we'll extend our FAQ chatbot to use more advanced memory techniques and implement a basic RAG (Retrieval Augmented Generation) system."
   ],
   "id": "f3450c81c4cf19ae"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-09-17T16:43:28.191426Z"
    }
   },
   "source": [
    "# Install required packages\"\n",
    "!pip install langchain faiss-cpu sentence-transformers"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 1. SummaryMemory: The Executive Assistant Analogy\n",
    "\n",
    "Think of SummaryMemory like an executive assistant who takes detailed meeting notes but provides you with concise summaries. Instead of remembering every single word from a 2-hour meeting, your assistant gives you the key points, decisions made, and action items.\n",
    "\n",
    "**How it works:**\n",
    "- Stores a running summary of the conversation rather than verbatim text\n",
    "- Uses the LLM itself to generate summaries of past interactions\n",
    "- More efficient for long conversations as it doesn't grow linearly with chat length\n",
    "- Maintains context without consuming excessive tokens\n",
    "\n",
    "**When to use it:**\n",
    "- Long conversations where full history would be too expensive\n",
    "- When you need to maintain context over many interactions\n",
    "- Situations where the gist of past conversations matters more than exact wording"
   ],
   "id": "57591e29ae829b33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T18:20:42.171123Z",
     "start_time": "2025-09-17T18:20:19.822731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationSummaryMemory\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Initialize OpenRouter LLM (using the free model from previous session)\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"meta-llama/llama-3.1-8b-instruct\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    openai_api_key='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',\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    ")\n",
    "\n",
    "# Initialize summary memory\n",
    "summary_memory = ConversationSummaryMemory(\n",
    "    llm=llm,\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# Example usage\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"What subscription plans do you offer?\"},\n",
    "    {\"output\": \"We offer Basic ($10), Pro ($25), and Enterprise ($50) plans.\"}\n",
    ")\n",
    "\n",
    "summary_memory.save_context(\n",
    "    {\"input\": \"Which includes phone support?\"},\n",
    "    {\"output\": \"Pro and Enterprise plans include phone support.\"}\n",
    ")\n",
    "\n",
    "# View the summarized memory\n",
    "print(\"Summary Memory Content:\")\n",
    "print(summary_memory.load_memory_variables({})['chat_history'])"
   ],
   "id": "b8ce4b9320ecb3b4",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moonwalking\\AppData\\Local\\Temp\\ipykernel_2912\\2666078106.py:17: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  summary_memory = ConversationSummaryMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Memory Content:\n",
      "[SystemMessage(content='Current summary:\\nThe human asks about subscription plans. The AI offers Basic ($10), Pro ($25), and Enterprise ($50) plans.\\n\\nNew lines of conversation:\\nHuman: Which includes phone support?\\nAI: Pro and Enterprise plans include phone support.\\n\\nNew summary:\\nThe human asks about subscription plans. The AI offers Basic ($10), Pro ($25), and Enterprise ($50) plans. The Pro and Enterprise plans include phone support.', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 2. VectorStoreRetrieverMemory: The Library Analogy\n",
    "\n",
    "Imagine you're a researcher in a vast library. Instead of memorizing every book, you have a skilled librarian who can quickly find the most relevant books based on your current question. VectorStoreRetrieverMemory works exactly like this librarian.\n",
    "\n",
    "**How it works:**\n",
    "- Stores conversation snippets in a vector database\n",
    "- Uses semantic similarity to find relevant past conversations\n",
    "- Retrieves only the most contextually relevant memories\n",
    "- Doesn't require remembering everything, just what's potentially useful\n",
    "\n",
    "**Key components:**\n",
    "- Embeddings: Convert text to numerical representations\n",
    "- Vector store: Database optimized for similarity search\n",
    "- Retriever: Algorithm that finds the most relevant memories"
   ],
   "id": "7e4d89090161b24c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T18:27:47.530819Z",
     "start_time": "2025-09-17T18:27:43.794384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "# Create sample conversation memories\n",
    "memory_documents = [\n",
    "    Document(page_content=\"Customer asked about subscription plans. We offer Basic, Pro, Enterprise.\"),\n",
    "    Document(page_content=\"Customer inquired about phone support. Available in Pro and Enterprise plans.\"),\n",
    "    Document(page_content=\"Customer asked about system requirements. Minimum 4GB RAM, works on Windows, Mac, Linux.\"),\n",
    "    Document(page_content=\"Customer requested refund information. 30-day money-back guarantee for all plans.\")\n",
    "]\n",
    "\n",
    "# Create vector store\n",
    "vectorstore = FAISS.from_documents(memory_documents, embeddings)\n",
    "\n",
    "# Create retriever\n",
    "retriever = vectorstore.as_retriever(search_kwargs=dict(k=2))\n",
    "\n",
    "# Initialize vector memory\n",
    "vector_memory = VectorStoreRetrieverMemory(\n",
    "    retriever=retriever,\n",
    "    memory_key=\"recent_context\",\n",
    "    return_docs=True\n",
    ")\n",
    "\n",
    "# Test the memory retrieval\n",
    "relevant_memories = vector_memory.load_memory_variables(\n",
    "    {\"prompt\": \"What support options are available?\"}\n",
    ")\n",
    "print(\"Relevant memories for support question:\")\n",
    "for doc in relevant_memories[\"recent_context\"]:\n",
    "    print(f\"- {doc.page_content}\")"
   ],
   "id": "3126ea4c5eedc409",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant memories for support question:\n",
      "- Customer inquired about phone support. Available in Pro and Enterprise plans.\n",
      "- Customer asked about subscription plans. We offer Basic, Pro, Enterprise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moonwalking\\AppData\\Local\\Temp\\ipykernel_2912\\1316091875.py:26: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  vector_memory = VectorStoreRetrieverMemory(\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 3. Embeddings + FAISS: The GPS for Text Analogy\n",
    "\n",
    "Think of embeddings as a sophisticated GPS system for text. Just as a GPS converts physical addresses into coordinates that can be mathematically compared, embeddings convert text into numerical vectors that capture semantic meaning.\n",
    "\n",
    "**Embeddings explained:**\n",
    "- Transform text into high-dimensional vectors (typically 300-1000 dimensions)\n",
    "- Semantically similar texts have similar vector representations\n",
    "- Enable mathematical operations on text (e.g., \"king\" - \"man\" + \"woman\" ≈ \"queen\")\n",
    "\n",
    "**FAISS (Facebook AI Similarity Search):**\n",
    "- Specialized library for efficient similarity search in high-dimensional spaces\n",
    "- Can quickly find the most similar vectors from millions of possibilities\n",
    "- Optimized for speed and memory efficiency\n",
    "\n",
    "**Why this combination matters:**\n",
    "- Allows finding semantically related content without exact keyword matches\n",
    "- Enables efficient retrieval from large knowledge bases\n",
    "- Forms the foundation for modern retrieval systems"
   ],
   "id": "2d4f5a08c8f4e28a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T18:30:30.550297Z",
     "start_time": "2025-09-17T18:30:26.214823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Sample documents for our knowledge base\n",
    "documents = [\n",
    "    \"Our company offers three subscription plans: Basic ($10/mo), Pro ($25/mo), and Enterprise ($50/mo)\",\n",
    "    \"All plans include 24/7 email support. Pro and Enterprise include phone support.\",\n",
    "    \"Enterprise plan includes a dedicated account manager and custom integrations.\",\n",
    "    \"Our software works on Windows, Mac, and Linux systems with minimum 4GB RAM.\",\n",
    "    \"Return policy: 30-day money-back guarantee for all plans.\",\n",
    "    \"Setup process takes approximately 15 minutes with our guided installation wizard.\"\n",
    "]\n",
    "\n",
    "# Convert to Document objects\n",
    "doc_objects = [Document(page_content=doc) for doc in documents]\n",
    "\n",
    "# Create FAISS vector store\n",
    "vectorstore = FAISS.from_documents(doc_objects, embeddings)\n",
    "\n",
    "# Test similarity search\n",
    "query = \"What support options come with the Pro plan?\"\n",
    "similar_docs = vectorstore.similarity_search(query, k=2)\n",
    "\n",
    "print(f\"Query: {query}\")\n",
    "print(\"Most relevant documents:\")\n",
    "for i, doc in enumerate(similar_docs):\n",
    "    print(f\"{i+1}. {doc.page_content}\")"
   ],
   "id": "51974872439cd370",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What support options come with the Pro plan?\n",
      "Most relevant documents:\n",
      "1. All plans include 24/7 email support. Pro and Enterprise include phone support.\n",
      "2. Our company offers three subscription plans: Basic ($10/mo), Pro ($25/mo), and Enterprise ($50/mo)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### 4. RAG Workflow Fundamentals: The Research Assistant Analogy\n",
    "\n",
    "Imagine you're writing a research paper. Instead of relying solely on your existing knowledge (like a standard LLM), you have a research assistant who:\n",
    "1. Listens to your question\n",
    "2. Goes to the library to find relevant sources\n",
    "3. Brings back the most pertinent information\n",
    "4. Helps you craft a well-informed answer\n",
    "\n",
    "This is exactly what RAG (Retrieval Augmented Generation) does.\n",
    "\n",
    "**RAG Components:**\n",
    "1. **Retriever**: The \"library goer\" that finds relevant information\n",
    "2. **Generator**: The \"writer\" that crafts the response\n",
    "3. **Knowledge Base**: The \"library\" of information\n",
    "\n",
    "**Why RAG matters:**\n",
    "- Grounds responses in factual information\n",
    "- Allows incorporating up-to-date knowledge\n",
    "- Reduces hallucination by providing source material\n",
    "- Enables domain-specific expertise without retraining models"
   ],
   "id": "9a3a1a20f296cb38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T18:39:47.938983Z",
     "start_time": "2025-09-17T18:39:43.360494Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "\n",
    "# Create a simpler memory that works with RAG\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    k=5,  # Keep last 5 exchanges\n",
    "    return_messages=True,\n",
    "    output_key='answer'\n",
    ")\n",
    "\n",
    "# Create a RAG chain that works with conversation memory\n",
    "qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vectorstore.as_retriever(search_kwargs=dict(k=3)),\n",
    "    memory=memory,\n",
    "    return_source_documents=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Test the RAG system\n",
    "response = qa_chain({\"question\": \"What subscription plans do you offer and what support is included in each?\"})\n",
    "print(\"Answer:\", response['answer'])\n",
    "print(\"\\nSource documents used:\")\n",
    "for i, doc in enumerate(response['source_documents']):\n",
    "    print(f\"{i+1}. {doc.page_content}\")"
   ],
   "id": "3077922678d69653",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moonwalking\\AppData\\Local\\Temp\\ipykernel_2912\\3262762095.py:5: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferWindowMemory(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new StuffDocumentsChain chain...\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: Use the following pieces of context to answer the user's question.\n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Our company offers three subscription plans: Basic ($10/mo), Pro ($25/mo), and Enterprise ($50/mo)\n",
      "\n",
      "All plans include 24/7 email support. Pro and Enterprise include phone support.\n",
      "\n",
      "Enterprise plan includes a dedicated account manager and custom integrations.\n",
      "Human: What subscription plans do you offer and what support is included in each?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "Answer: We offer three subscription plans: Basic ($10/mo), Pro ($25/mo), and Enterprise ($50/mo).\n",
      "\n",
      "Here's a breakdown of the support included in each plan:\n",
      "\n",
      "* All plans include 24/7 email support.\n",
      "* Pro and Enterprise plans include phone support, in addition to email support.\n",
      "* The Enterprise plan also includes a dedicated account manager and custom integrations.\n",
      "\n",
      "Source documents used:\n",
      "1. Our company offers three subscription plans: Basic ($10/mo), Pro ($25/mo), and Enterprise ($50/mo)\n",
      "2. All plans include 24/7 email support. Pro and Enterprise include phone support.\n",
      "3. Enterprise plan includes a dedicated account manager and custom integrations.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Hands-On: Extend the FAQ bot to a mini-RAG over docs",
   "id": "529775f3b550e1c8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T18:49:41.087858Z",
     "start_time": "2025-09-17T18:49:25.174219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's create a simplified version that works with OpenRouter\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "class AdvancedFAQBot:\n",
    "    def __init__(self, llm, knowledge_docs):\n",
    "        self.llm = llm\n",
    "\n",
    "        # Initialize embeddings and vector store\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "        self.vectorstore = FAISS.from_documents(knowledge_docs, self.embeddings)\n",
    "\n",
    "        # Use simpler memory that works better with RAG\n",
    "        self.memory = ConversationBufferWindowMemory(\n",
    "            k=3,  # Keep last 3 exchanges\n",
    "            memory_key=\"chat_history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "\n",
    "        # Create comprehensive prompt\n",
    "        self.prompt = PromptTemplate(\n",
    "            template=\"\"\"As a customer support agent, use the following information to answer the question:\n",
    "\n",
    "Knowledge Base Context:\n",
    "{relevant_context}\n",
    "\n",
    "Conversation History:\n",
    "{chat_history}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Please provide a helpful, accurate answer based on the context provided. If the context doesn't contain the answer, politely say you don't know.\n",
    "\n",
    "Answer:\"\"\",\n",
    "            input_variables=[\"relevant_context\", \"chat_history\", \"question\"]\n",
    "        )\n",
    "\n",
    "        # Create the chain\n",
    "        self.chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=self.prompt,\n",
    "            verbose=False\n",
    "        )\n",
    "\n",
    "    def ask(self, question):\n",
    "        # Get relevant context from knowledge base using similarity search\n",
    "        similar_docs = self.vectorstore.similarity_search(question, k=2)\n",
    "        context_info = \"\\n\".join([doc.page_content for doc in similar_docs])\n",
    "\n",
    "        # Get conversation history\n",
    "        history = self.memory.load_memory_variables({})[\"chat_history\"]\n",
    "\n",
    "        # Get response\n",
    "        response = self.chain.run(\n",
    "            relevant_context=context_info,\n",
    "            chat_history=history,\n",
    "            question=question\n",
    "        )\n",
    "\n",
    "        # Save to memory\n",
    "        self.memory.save_context({\"input\": question}, {\"output\": response})\n",
    "\n",
    "        return response\n",
    "\n",
    "# Prepare knowledge documents\n",
    "knowledge_documents = [\n",
    "    Document(page_content=\"Subscription Plans: Basic ($10/month), Pro ($25/month), Enterprise ($50/month)\"),\n",
    "    Document(page_content=\"Support: All plans include email support. Phone support for Pro and Enterprise. Dedicated manager for Enterprise.\"),\n",
    "    Document(page_content=\"System Requirements: Windows 10+, macOS 10.14+, Linux Ubuntu 16.04+. Minimum 4GB RAM.\"),\n",
    "    Document(page_content=\"Refund Policy: 30-day money-back guarantee for all subscription plans.\"),\n",
    "    Document(page_content=\"Setup: Average setup time 15 minutes. Guided installation wizard available.\"),\n",
    "    Document(page_content=\"Integration: API access available for Pro and Enterprise plans. Webhooks supported.\"),\n",
    "]\n",
    "\n",
    "# Initialize the advanced bot\n",
    "advanced_bot = AdvancedFAQBot(llm, knowledge_documents)\n",
    "\n",
    "# Test conversation\n",
    "questions = [\n",
    "    \"What are your subscription options?\",\n",
    "    \"Which plan would you recommend for a small business?\",\n",
    "    \"What if I need to get a refund?\",\n",
    "    \"How difficult is the setup process?\",\n",
    "    \"Do you offer API access?\"\n",
    "]\n",
    "\n",
    "print(\"Advanced FAQ Bot Demonstration:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    answer = advanced_bot.ask(question)\n",
    "    print(f\"A: {answer}\")\n",
    "    print(\"-\" * 50)"
   ],
   "id": "b4585a9d13df65b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advanced FAQ Bot Demonstration:\n",
      "==================================================\n",
      "\n",
      "Q: What are your subscription options?\n",
      "A: We offer three subscription plans to choose from: Basic, Pro, and Enterprise. Our Basic plan is $10/month, our Pro plan is $25/month, and our Enterprise plan is $50/month. If you're unsure which plan is right for you, I'd be happy to help you compare the features and benefits of each.\n",
      "--------------------------------------------------\n",
      "\n",
      "Q: Which plan would you recommend for a small business?\n",
      "A: Based on our conversation, I would recommend the Pro plan for a small business. This plan offers phone support, which may be beneficial for small businesses that need immediate assistance, in addition to email support. The Pro plan also seems to offer a good balance between cost and features, as it's priced at $25/month, which is lower than the Enterprise plan but still offers additional support beyond the Basic plan. However, if you'd like a more detailed comparison of the features and benefits of each plan, I'd be happy to help you with that.\n",
      "--------------------------------------------------\n",
      "\n",
      "Q: What if I need to get a refund?\n",
      "A: We offer a 30-day money-back guarantee for all subscription plans. This means that if you're not satisfied with your subscription, you can request a refund within 30 days of signing up. If you have any questions or concerns about the refund process, I'd be happy to help. Please let me know if there's anything else I can do for you.\n",
      "--------------------------------------------------\n",
      "\n",
      "Q: How difficult is the setup process?\n",
      "A: The setup process is relatively straightforward, taking an average of 15 minutes to complete. Additionally, a guided installation wizard is available to assist you through the process.\n",
      "--------------------------------------------------\n",
      "\n",
      "Q: Do you offer API access?\n",
      "A: According to our Knowledge Base, API access is available for Pro and Enterprise plans.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Case Study: Internal knowledge-base assistant for an SME",
   "id": "fcf14db35701f4ba"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-17T18:54:15.951776Z",
     "start_time": "2025-09-17T18:53:55.094625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Let's create a simplified version of SMEKnowledgeAssistant that works\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.schema import Document\n",
    "\n",
    "class SMEKnowledgeAssistant:\n",
    "    def __init__(self, llm, company_docs, product_docs, policy_docs):\n",
    "        self.llm = llm\n",
    "        self.embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "        # Create separate vector stores for different knowledge types\n",
    "        self.company_store = FAISS.from_documents(company_docs, self.embeddings)\n",
    "        self.product_store = FAISS.from_documents(product_docs, self.embeddings)\n",
    "        self.policy_store = FAISS.from_documents(policy_docs, self.embeddings)\n",
    "\n",
    "        # Use simpler memory\n",
    "        self.memory = ConversationBufferWindowMemory(\n",
    "            k=3,\n",
    "            memory_key=\"history\",\n",
    "            return_messages=True\n",
    "        )\n",
    "\n",
    "        # Create specialized prompt\n",
    "        self.prompt = PromptTemplate(\n",
    "            template=\"\"\"As an internal knowledge assistant for {company_name}, use the following information to answer the question.\n",
    "\n",
    "Company Information:\n",
    "{company_info}\n",
    "\n",
    "Product Details:\n",
    "{product_info}\n",
    "\n",
    "Policies & Procedures:\n",
    "{policy_info}\n",
    "\n",
    "Conversation History:\n",
    "{history}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Please provide a comprehensive answer based on the available information. If information is missing, suggest where to find it or who to contact.\n",
    "\n",
    "Answer:\"\"\",\n",
    "            input_variables=[\"company_name\", \"company_info\", \"product_info\", \"policy_info\", \"history\", \"question\"]\n",
    "        )\n",
    "\n",
    "        # Create chain without memory (we'll handle memory separately)\n",
    "        self.chain = LLMChain(\n",
    "            llm=llm,\n",
    "            prompt=self.prompt,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "    def query(self, question, company_name=\"our company\"):\n",
    "        # Retrieve relevant information from all knowledge bases\n",
    "        company_info = self.company_store.similarity_search(question, k=2)\n",
    "        product_info = self.product_store.similarity_search(question, k=2)\n",
    "        policy_info = self.policy_store.similarity_search(question, k=2)\n",
    "\n",
    "        # Format the information\n",
    "        company_text = \"\\n\".join([doc.page_content for doc in company_info])\n",
    "        product_text = \"\\n\".join([doc.page_content for doc in product_info])\n",
    "        policy_text = \"\\n\".join([doc.page_content for doc in policy_info])\n",
    "\n",
    "        # Get conversation history\n",
    "        history = self.memory.load_memory_variables({})[\"history\"]\n",
    "\n",
    "        # Get response\n",
    "        response = self.chain.run(\n",
    "            company_name=company_name,\n",
    "            company_info=company_text,\n",
    "            product_info=product_text,\n",
    "            policy_info=policy_text,\n",
    "            history=history,\n",
    "            question=question\n",
    "        )\n",
    "\n",
    "        # Save to memory\n",
    "        self.memory.save_context({\"input\": question}, {\"output\": response})\n",
    "\n",
    "        return response\n",
    "\n",
    "# Sample knowledge base documents for an SME\n",
    "company_docs = [\n",
    "    Document(page_content=\"Company founded in 2018. Headquarters in San Francisco. 50 employees globally.\"),\n",
    "    Document(page_content=\"Mission: To simplify business operations through innovative software solutions.\"),\n",
    "    Document(page_content=\"Departments: Engineering, Sales, Customer Support, Marketing, Operations.\"),\n",
    "    Document(page_content=\"Key executives: CEO - Jane Smith, CTO - John Doe, CFO - Alice Johnson.\"),\n",
    "]\n",
    "\n",
    "product_docs = [\n",
    "    Document(page_content=\"Flagship product: OperationsHub - workflow automation platform.\"),\n",
    "    Document(page_content=\"DataSync tool: Real-time data integration across platforms.\"),\n",
    "    Document(page_content=\"ReportBuilder: Custom analytics and reporting dashboard.\"),\n",
    "    Document(page_content=\"Mobile app: iOS and Android apps available for all products.\"),\n",
    "]\n",
    "\n",
    "policy_docs = [\n",
    "    Document(page_content=\"Vacation policy: 15 days PTO for new employees, increasing with tenure.\"),\n",
    "    Document(page_content=\"Expense policy: Submit expenses within 30 days through Expensify system.\"),\n",
    "    Document(page_content=\"Remote work: Hybrid model - 3 days in office, 2 days remote.\"),\n",
    "    Document(page_content=\"IT policy: Company devices only for work. Regular security training required.\"),\n",
    "]\n",
    "\n",
    "# Initialize the SME assistant\n",
    "sme_assistant = SMEKnowledgeAssistant(llm, company_docs, product_docs, policy_docs)\n",
    "\n",
    "# Test various internal queries\n",
    "internal_questions = [\n",
    "    \"What's our company's mission?\",\n",
    "    \"What products do we offer?\",\n",
    "    \"What's the vacation policy for employees?\",\n",
    "    \"Who are our key executives?\",\n",
    "    \"What's the remote work policy?\"\n",
    "]\n",
    "\n",
    "print(\"SME Knowledge Assistant Demonstration:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for question in internal_questions:\n",
    "    print(f\"\\nQ: {question}\")\n",
    "    answer = sme_assistant.query(question, \"TechSolutions Inc\")\n",
    "    print(f\"A: {answer}\")\n",
    "    print(\"-\" * 60)"
   ],
   "id": "b57db98634ee29ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SME Knowledge Assistant Demonstration:\n",
      "============================================================\n",
      "\n",
      "Q: What's our company's mission?\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mAs an internal knowledge assistant for TechSolutions Inc, use the following information to answer the question.\n",
      "\n",
      "Company Information:\n",
      "Mission: To simplify business operations through innovative software solutions.\n",
      "Key executives: CEO - Jane Smith, CTO - John Doe, CFO - Alice Johnson.\n",
      "\n",
      "Product Details:\n",
      "Flagship product: OperationsHub - workflow automation platform.\n",
      "ReportBuilder: Custom analytics and reporting dashboard.\n",
      "\n",
      "Policies & Procedures:\n",
      "Remote work: Hybrid model - 3 days in office, 2 days remote.\n",
      "IT policy: Company devices only for work. Regular security training required.\n",
      "\n",
      "Conversation History:\n",
      "[]\n",
      "\n",
      "Question: What's our company's mission?\n",
      "\n",
      "Please provide a comprehensive answer based on the available information. If information is missing, suggest where to find it or who to contact.\n",
      "\n",
      "Answer:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "A: Our company's mission is to simplify business operations through innovative software solutions. This information is readily available and can be found in the Company Information section.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Q: What products do we offer?\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mAs an internal knowledge assistant for TechSolutions Inc, use the following information to answer the question.\n",
      "\n",
      "Company Information:\n",
      "Departments: Engineering, Sales, Customer Support, Marketing, Operations.\n",
      "Mission: To simplify business operations through innovative software solutions.\n",
      "\n",
      "Product Details:\n",
      "Mobile app: iOS and Android apps available for all products.\n",
      "Flagship product: OperationsHub - workflow automation platform.\n",
      "\n",
      "Policies & Procedures:\n",
      "IT policy: Company devices only for work. Regular security training required.\n",
      "Remote work: Hybrid model - 3 days in office, 2 days remote.\n",
      "\n",
      "Conversation History:\n",
      "[HumanMessage(content=\"What's our company's mission?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Our company's mission is to simplify business operations through innovative software solutions. This information is readily available and can be found in the Company Information section.\", additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "Question: What products do we offer?\n",
      "\n",
      "Please provide a comprehensive answer based on the available information. If information is missing, suggest where to find it or who to contact.\n",
      "\n",
      "Answer:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "A: Based on the provided information, I can tell you that TechSolutions Inc offers several products, but the specific details about each product are limited. Here's what I can confirm:\n",
      "\n",
      "1. **Flagship product:** OperationsHub - a workflow automation platform. This is the only product mentioned by name in the provided information.\n",
      "2. **Mobile app:** The company has iOS and Android apps available for all products. However, the specific products that have mobile apps are not explicitly stated.\n",
      "\n",
      "Unfortunately, I couldn't find any information about other products offered by TechSolutions Inc. If you need more information, I suggest checking the Product Details section or reaching out to the relevant department (e.g., Engineering, Sales, or Marketing) for more information.\n",
      "\n",
      "If you're looking for a comprehensive list of products or detailed product information, you may want to contact:\n",
      "\n",
      "* Engineering department: For technical product information and specifications.\n",
      "* Sales department: For product offerings and pricing information.\n",
      "* Marketing department: For product branding, positioning, and promotional materials.\n",
      "\n",
      "Please note that these departments may have the most up-to-date information about the company's products.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Q: What's the vacation policy for employees?\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mAs an internal knowledge assistant for TechSolutions Inc, use the following information to answer the question.\n",
      "\n",
      "Company Information:\n",
      "Company founded in 2018. Headquarters in San Francisco. 50 employees globally.\n",
      "Key executives: CEO - Jane Smith, CTO - John Doe, CFO - Alice Johnson.\n",
      "\n",
      "Product Details:\n",
      "Flagship product: OperationsHub - workflow automation platform.\n",
      "Mobile app: iOS and Android apps available for all products.\n",
      "\n",
      "Policies & Procedures:\n",
      "Vacation policy: 15 days PTO for new employees, increasing with tenure.\n",
      "Expense policy: Submit expenses within 30 days through Expensify system.\n",
      "\n",
      "Conversation History:\n",
      "[HumanMessage(content=\"What's our company's mission?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Our company's mission is to simplify business operations through innovative software solutions. This information is readily available and can be found in the Company Information section.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What products do we offer?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Based on the provided information, I can tell you that TechSolutions Inc offers several products, but the specific details about each product are limited. Here's what I can confirm:\\n\\n1. **Flagship product:** OperationsHub - a workflow automation platform. This is the only product mentioned by name in the provided information.\\n2. **Mobile app:** The company has iOS and Android apps available for all products. However, the specific products that have mobile apps are not explicitly stated.\\n\\nUnfortunately, I couldn't find any information about other products offered by TechSolutions Inc. If you need more information, I suggest checking the Product Details section or reaching out to the relevant department (e.g., Engineering, Sales, or Marketing) for more information.\\n\\nIf you're looking for a comprehensive list of products or detailed product information, you may want to contact:\\n\\n* Engineering department: For technical product information and specifications.\\n* Sales department: For product offerings and pricing information.\\n* Marketing department: For product branding, positioning, and promotional materials.\\n\\nPlease note that these departments may have the most up-to-date information about the company's products.\", additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "Question: What's the vacation policy for employees?\n",
      "\n",
      "Please provide a comprehensive answer based on the available information. If information is missing, suggest where to find it or who to contact.\n",
      "\n",
      "Answer:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "A: Our company's vacation policy is as follows: new employees are entitled to 15 days of Paid Time Off (PTO), which increases with their tenure. If you need more information or have specific questions about the policy, I suggest checking the Policies & Procedures section for the most up-to-date information or reaching out to the relevant department (e.g., HR or Finance).\n",
      "------------------------------------------------------------\n",
      "\n",
      "Q: Who are our key executives?\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mAs an internal knowledge assistant for TechSolutions Inc, use the following information to answer the question.\n",
      "\n",
      "Company Information:\n",
      "Key executives: CEO - Jane Smith, CTO - John Doe, CFO - Alice Johnson.\n",
      "Departments: Engineering, Sales, Customer Support, Marketing, Operations.\n",
      "\n",
      "Product Details:\n",
      "Flagship product: OperationsHub - workflow automation platform.\n",
      "ReportBuilder: Custom analytics and reporting dashboard.\n",
      "\n",
      "Policies & Procedures:\n",
      "IT policy: Company devices only for work. Regular security training required.\n",
      "Remote work: Hybrid model - 3 days in office, 2 days remote.\n",
      "\n",
      "Conversation History:\n",
      "[HumanMessage(content=\"What's our company's mission?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Our company's mission is to simplify business operations through innovative software solutions. This information is readily available and can be found in the Company Information section.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What products do we offer?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Based on the provided information, I can tell you that TechSolutions Inc offers several products, but the specific details about each product are limited. Here's what I can confirm:\\n\\n1. **Flagship product:** OperationsHub - a workflow automation platform. This is the only product mentioned by name in the provided information.\\n2. **Mobile app:** The company has iOS and Android apps available for all products. However, the specific products that have mobile apps are not explicitly stated.\\n\\nUnfortunately, I couldn't find any information about other products offered by TechSolutions Inc. If you need more information, I suggest checking the Product Details section or reaching out to the relevant department (e.g., Engineering, Sales, or Marketing) for more information.\\n\\nIf you're looking for a comprehensive list of products or detailed product information, you may want to contact:\\n\\n* Engineering department: For technical product information and specifications.\\n* Sales department: For product offerings and pricing information.\\n* Marketing department: For product branding, positioning, and promotional materials.\\n\\nPlease note that these departments may have the most up-to-date information about the company's products.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"What's the vacation policy for employees?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Our company's vacation policy is as follows: new employees are entitled to 15 days of Paid Time Off (PTO), which increases with their tenure. If you need more information or have specific questions about the policy, I suggest checking the Policies & Procedures section for the most up-to-date information or reaching out to the relevant department (e.g., HR or Finance).\", additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "Question: Who are our key executives?\n",
      "\n",
      "Please provide a comprehensive answer based on the available information. If information is missing, suggest where to find it or who to contact.\n",
      "\n",
      "Answer:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "A: Based on the provided information, the key executives at TechSolutions Inc are:\n",
      "\n",
      "1. **CEO (Chief Executive Officer)**: Jane Smith\n",
      "2. **CTO (Chief Technology Officer)**: John Doe\n",
      "3. **CFO (Chief Financial Officer)**: Alice Johnson\n",
      "\n",
      "This information is available in the **Company Information** section. If you need more information about the company's organizational structure or would like to know the contact details for these executives, I suggest checking the Company Information section or reaching out to the relevant department (e.g., HR or Finance) for more information.\n",
      "------------------------------------------------------------\n",
      "\n",
      "Q: What's the remote work policy?\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mAs an internal knowledge assistant for TechSolutions Inc, use the following information to answer the question.\n",
      "\n",
      "Company Information:\n",
      "Key executives: CEO - Jane Smith, CTO - John Doe, CFO - Alice Johnson.\n",
      "Company founded in 2018. Headquarters in San Francisco. 50 employees globally.\n",
      "\n",
      "Product Details:\n",
      "Flagship product: OperationsHub - workflow automation platform.\n",
      "DataSync tool: Real-time data integration across platforms.\n",
      "\n",
      "Policies & Procedures:\n",
      "Remote work: Hybrid model - 3 days in office, 2 days remote.\n",
      "IT policy: Company devices only for work. Regular security training required.\n",
      "\n",
      "Conversation History:\n",
      "[HumanMessage(content='What products do we offer?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Based on the provided information, I can tell you that TechSolutions Inc offers several products, but the specific details about each product are limited. Here's what I can confirm:\\n\\n1. **Flagship product:** OperationsHub - a workflow automation platform. This is the only product mentioned by name in the provided information.\\n2. **Mobile app:** The company has iOS and Android apps available for all products. However, the specific products that have mobile apps are not explicitly stated.\\n\\nUnfortunately, I couldn't find any information about other products offered by TechSolutions Inc. If you need more information, I suggest checking the Product Details section or reaching out to the relevant department (e.g., Engineering, Sales, or Marketing) for more information.\\n\\nIf you're looking for a comprehensive list of products or detailed product information, you may want to contact:\\n\\n* Engineering department: For technical product information and specifications.\\n* Sales department: For product offerings and pricing information.\\n* Marketing department: For product branding, positioning, and promotional materials.\\n\\nPlease note that these departments may have the most up-to-date information about the company's products.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"What's the vacation policy for employees?\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Our company's vacation policy is as follows: new employees are entitled to 15 days of Paid Time Off (PTO), which increases with their tenure. If you need more information or have specific questions about the policy, I suggest checking the Policies & Procedures section for the most up-to-date information or reaching out to the relevant department (e.g., HR or Finance).\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Who are our key executives?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Based on the provided information, the key executives at TechSolutions Inc are:\\n\\n1. **CEO (Chief Executive Officer)**: Jane Smith\\n2. **CTO (Chief Technology Officer)**: John Doe\\n3. **CFO (Chief Financial Officer)**: Alice Johnson\\n\\nThis information is available in the **Company Information** section. If you need more information about the company's organizational structure or would like to know the contact details for these executives, I suggest checking the Company Information section or reaching out to the relevant department (e.g., HR or Finance) for more information.\", additional_kwargs={}, response_metadata={})]\n",
      "\n",
      "Question: What's the remote work policy?\n",
      "\n",
      "Please provide a comprehensive answer based on the available information. If information is missing, suggest where to find it or who to contact.\n",
      "\n",
      "Answer:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "A: Based on the provided information, TechSolutions Inc's remote work policy is as follows:\n",
      "\n",
      "We have a hybrid remote work model, where employees work from the office for 3 days and remotely for 2 days. Unfortunately, I couldn't find any information about the specific rules or guidelines for remote work, such as working hours, communication expectations, or performance monitoring.\n",
      "\n",
      "If you need more information about the remote work policy, I suggest checking the Policies & Procedures section for the most up-to-date information or reaching out to the HR department for clarification. They may have the most up-to-date information about our company's remote work policies and procedures.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Implementation Notes and Best Practices\n",
    "\n",
    "### Memory Management Strategies\n",
    "1. **Hybrid Approach**: Combine different memory types for optimal performance\n",
    "2. **Memory Window**: Use buffer window memory for recent context + summary memory for long-term context\n",
    "3. **Cost Consideration**: Summary memory uses additional LLM calls but saves tokens in long run\n",
    "\n",
    "### RAG Optimization Tips\n",
    "1. **Chunk Size**: Experiment with different document chunk sizes (200-500 words often works well)\n",
    "2. **Retrieval Count**: Retrieve 3-5 documents for balance between context and token usage\n",
    "3. **Relevance Threshold**: Implement score thresholds to filter out irrelevant documents\n",
    "\n",
    "### Performance Considerations\n",
    "1. **Embedding Model Choice**: Balance between quality and speed (all-MiniLM-L6-v2 is good for development)\n",
    "2. **Vector Database**: FAISS is great for development; consider Pinecone or Weaviate for production\n",
    "3. **Caching**: Implement caching for frequent queries to reduce API costs\n",
    "\n",
    "### Error Handling\n",
    "1. **Fallback Mechanisms**: Implement fallbacks when retrieval returns empty results\n",
    "2. **Timeout Handling**: Set appropriate timeouts for vector search operations\n",
    "3. **Rate Limiting**: Respect API rate limits, especially with free-tier models\n",
    "\n",
    "### Evaluation Metrics\n",
    "1. **Retrieval Accuracy**: How often retrieved documents are relevant to the query\n",
    "2. **Answer Quality**: Human evaluation of response usefulness and accuracy\n",
    "3. **Latency**: Response time from query to answer\n",
    "4. **Cost Efficiency**: Token usage per conversation\n",
    "\n",
    "This comprehensive approach provides a robust foundation for building knowledge-aware conversational agents that can scale from simple FAQ bots to sophisticated internal knowledge assistants."
   ],
   "id": "bd6715b7b183a0e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Additional configuration for OpenRouter models\n",
    "# If you encounter issues with the default model, try these alternatives:\n",
    "\n",
    "# Option 1: Google Gemini Pro (if available)\n",
    "gemini_llm = ChatOpenAI(\n",
    "    model=\"google/gemini-pro\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    openai_api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    ")\n",
    "\n",
    "# Option 2: Mistral 7B\n",
    "mistral_llm = ChatOpenAI(\n",
    "    model=\"mistralai/mistral-7b-instruct\",\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    openai_api_key=os.environ[\"OPENROUTER_API_KEY\"],\n",
    "    temperature=0.7,\n",
    "    max_tokens=256,\n",
    ")\n",
    "\n",
    "# Option 3: Check available models (if none work)\n",
    "import requests\n",
    "\n",
    "def check_available_models():\n",
    "    url = \"https://openrouter.ai/api/v1/models\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        models = response.json().get('data', [])\n",
    "        free_models = [model for model in models if model.get('pricing', {}).get('prompt') == '0']\n",
    "        print(\"Available free models:\")\n",
    "        for model in free_models:\n",
    "            print(f\"- {model['id']}\")\n",
    "    else:\n",
    "        print(\"Error fetching models\")\n",
    "\n",
    "# Uncomment to check available models if needed\n",
    "# check_available_models()"
   ],
   "id": "b6685da9f0be8531"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
